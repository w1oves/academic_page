
# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">In Submitting</div><img src='images/rein.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Stronger, Fewer, & Superior: Harnessing Vision Foundation Models for Domain Generalized Semantic Segmentation](https://arxiv.org/pdf/2312.04265.pdf) \\
**Zhixiang Wei***, Lin Chen*, Yi Jin*, Xiaoxiao Ma, Tianle Liu, Pengyang Ling, Ben Wang, Huaian Chen, Jinjin Zheng

[**Code**](https://github.com/w1oves/Rein) <strong><span class='show_paper_citations' data='4FA6C0AAAAAJ:qjMakFHDy7sC'></span></strong>

- We propose the Reins framework, which efficiently fine-tunes vision foundation models for the domain generalized semantic segmentation (DGSS) task with just 1% trainable parameters, surprisingly surpassing full parameter fine-tuning. And Reins builds a new SOTA in various DGSS benchmarks.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ICCV 2023</div><img src='images/dtp.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Disentangle then Parse: Night-time Semantic Segmentation with Illumination Disentanglement](https://arxiv.org/pdf/2307.09362.pdf) \\
**Zhixiang Wei***, Lin Chen*, Tao Tu, Huaian Chen, Pengyang Ling, Yi Jin

[**Code**](https://github.com/w1oves/DTP)
  - We propose a novel nigh-time semantic segmentation paradigm, i.e., disentangle then parse (DTP), which explicitly disentangles night-time images into light-invariant reflectance and light-specific illumination components and then recognizes semantics based on their adaptive fusion.
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeurIPS 2022 <span style="color:red">(Spotlight)</span></div><img src='images/ddb.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Deliberated Domain Bridging for Domain Adaptive Semantic Segmentation](https://arxiv.org/pdf/2209.07695.pdf) \\
Lin Chen*, **Zhixiang Wei***, Xin Jin*, Huaian Chen, Miao Zheng, Kai Chen, Yi Jin

[**Code**](https://github.com/xiaoachen98/DDB)
- We leverage the complementary characteristics of the coarse-wise and fine-wise data mixing techniques to progressively transfer the knowledge from the source to the target domain.
</div>
</div>


<div class='paper-box'><div class='paper-box-image'><div><div class="badge">CVPR 2022</div><img src='images/daln.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Reusing the Task-specific Classifier as a Discriminator: Discriminator-free Adversarial Domain Adaptation](https://openaccess.thecvf.com/content/CVPR2022/papers/Chen_Reusing_the_Task-Specific_Classifier_as_a_Discriminator_Discriminator-Free_Adversarial_Domain_CVPR_2022_paper.pdf) \\
Lin Chen*, Huaian Chen*, **Zhixiang Wei**, Xin Jin, Xiao Tan, Yi Jin, Enhong Chen

[**Code**](https://github.com/xiaoachen98/DALN)
- We reuse the category classifier as a discriminator to form a discriminator-free adversarial learning framework.
</div>
</div>